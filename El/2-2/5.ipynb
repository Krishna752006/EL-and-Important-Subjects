{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6c82db8",
   "metadata": {
    "id": "a6c82db8",
    "tags": []
   },
   "source": [
    "#  EXERCISE 3 :\n",
    "\n",
    "### Implement a sentiment analysis model with ScaledDotProduct attention mechanism using PyTorch .\n",
    "\n",
    "\n",
    "### Train the model using the given dataset and evaluate its performance on the test data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "85c1905c",
   "metadata": {
    "id": "85c1905c",
    "tags": []
   },
   "source": [
    "# Brief Steps\n",
    "\n",
    "1. Loading Dataset & Preprocessing\n",
    "\n",
    "   1) Data Loading & removing Missing text or label row\n",
    "   2) simple_tokenize & word-to-index mapping\n",
    "   3) Integer & Padded Sequences\n",
    "   4) Mapping Sentiment labels (positive, neutral, negative) are mapped to integers: 1, 2, and 0,\n",
    "   respectively.\n",
    "   5) Tokenized, padded sequences and labels to pytorch Tensors\n",
    "\n",
    "2. Splitting and DataLoader Setup\n",
    "\n",
    "   1) Train-Test Split 80 % & 20%\n",
    "   2) use PyTorch's DataLoader for batch and shuffling\n",
    "\n",
    "3. Implement Scaled Dot-Product Attention class\n",
    "\n",
    "    1) Attention Scores\n",
    "    2) Attention Weights:\n",
    "    3) Apply the softmax function to normalize the scores.\n",
    "\n",
    "4. Implement Sentiment Analysis Model Class\n",
    "\n",
    "    1) Embedding Layer:Maps input word indices to dense vector representations of size embedding_dim.\n",
    "    2) LSTM:Processes the sequence of word embeddings to capture temporal dependencies.\n",
    "    3) Attention Mechanism:\n",
    "    4) Fully Connected Layer: Maps the attention output to three sentiment classes (positive, neutral, negative).\n",
    "\n",
    "5. Training the Model\n",
    "    1) Choose a CrossEntropyLoss function or Mean Squared Error (MSE) based on problem statement\n",
    "    2) use any optimizer for weight updates or backpropagation\n",
    "    3) Train the model over multiple epochs and estimate validation loss and accuracy\n",
    "\n",
    "6. Model Evaluation\n",
    "\n",
    "    1) evaluate theTest Accuracy\n",
    "    2) Do Text Preprocessing & estimate the predictions on unseen data\n",
    "    3) Map the class to the sentiment category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4c2de",
   "metadata": {
    "id": "6bb4c2de",
    "tags": []
   },
   "source": [
    "## *****START TO SENTIMENTAL ANALYSIS *******"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd6a69",
   "metadata": {
    "id": "f5bd6a69",
    "tags": []
   },
   "source": [
    "##  1.Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c9ae91",
   "metadata": {
    "id": "02c9ae91",
    "tags": []
   },
   "source": [
    "###  1.  Import Necessary libraries"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd3dd88b-78b8-422c-8d53-6488d9e29571",
   "metadata": {
    "tags": []
   },
   "source": [
    "Your task is to import the necessary libraries required for preprocessing, model training, and evaluation for a sentiment analysis project using PyTorch and scikit-learn.\n",
    "\n",
    "1.Steps to Follow Import libraries \n",
    "    1)numpy for numerical operations.\n",
    "    2)pandas for handling tabular data.\n",
    "    3)train_test_split from sklearn.model_selection for splitting data into training and testing sets.\n",
    "    4)Import PyTorch modules for deep learning:\n",
    "        i)torch for tensor operations.\n",
    "        ii))torch.nn for defining neural networks.\n",
    "        iii)torch.optim for optimization algorithms.\n",
    "        iv)torch.utils.data to create datasets and dataloaders.\n",
    "        v) torch.nn.functional for activation functions and loss computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6428a822",
   "metadata": {
    "executionInfo": {
     "elapsed": 605,
     "status": "ok",
     "timestamp": 1737013120163,
     "user": {
      "displayName": "sri tulasi",
      "userId": "02259084893350954565"
     },
     "user_tz": -330
    },
    "id": "6428a822",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d308fa5c98f02ec0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ad78c",
   "metadata": {
    "id": "f96ad78c",
    "tags": []
   },
   "source": [
    "### 2. Load dataset and  Handle Missing Values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a75724a8",
   "metadata": {
    "id": "a75724a8",
    "tags": []
   },
   "source": [
    "Your task is to load and preprocess a dataset containing tweets and their corresponding sentiment labels. The goal is to clean the data by removing any missing values to ensure the model receives high-quality inputs.\n",
    "1.Load the dataset:\n",
    "    Use pandas to read the dataset from the CSV file named 'Tweets.csv'.\n",
    "    The data contains columns related to tweet text and sentiment labels.\n",
    "2.Preprocess the data:\n",
    "    Remove any rows that have missing values in the \"text\" and \"airline_sentiment\" columns using dropna().\n",
    "3.Check the dataset shape:\n",
    "    Print the shape of the cleaned dataset to confirm the number of valid entries remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9fc3a15",
   "metadata": {
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1737013152360,
     "user": {
      "displayName": "sri tulasi",
      "userId": "02259084893350954565"
     },
     "user_tz": -330
    },
    "id": "a9fc3a15",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a05e8c602f5f3e11",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('5. Tweets.csv', sep=',')  # Dataset path\n",
    "\n",
    "# Preprocess the data (basic cleaning)\n",
    "data = data.dropna(subset=[\"text\", \"airline_sentiment\"])  # Remove rows with missing data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b718a4ac-5749-4efa-8738-a4672b716c4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1737013154979,
     "user": {
      "displayName": "sri tulasi",
      "userId": "02259084893350954565"
     },
     "user_tz": -330
    },
    "id": "b718a4ac-5749-4efa-8738-a4672b716c4c",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-82d6cb28b1e4c87f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "9e3bd5de-7c5d-455f-d009-b4c0c82ff1a1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.           neutral\n",
       "1  @VirginAmerica plus you've added commercials t...          positive\n",
       "2  @VirginAmerica I didn't today... Must mean I n...           neutral"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"text\",\"airline_sentiment\"]][:3]   #Print the text and sentiment in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfefdd6",
   "metadata": {
    "id": "4dfefdd6",
    "tags": []
   },
   "source": [
    "### 3. Tokenization and assign word indicies"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a01bb43-6bb6-4152-9863-e9a2844f0df7",
   "metadata": {
    "id": "8a01bb43-6bb6-4152-9863-e9a2844f0df7",
    "tags": []
   },
   "source": [
    "You are tasked to\n",
    "\n",
    "1.Write a Tokenization Function:\n",
    "    - Define a function simple_tokenize(text) that takes a string as input, converts it to lowercase, \n",
    "      splits it into words, and returns a list of tokens.\n",
    "\n",
    "2.Create a Word-to-Index Dictionary: \n",
    "     - Write a loop to iterate through each tweet in the \"text\" column.\n",
    "     - For each tweet:\n",
    "         Tokenize the tweet using the simple_tokenize function.\n",
    "         Add each unique word to a dictionary (word_to_index),\n",
    "         assigning a unique numerical index to each word starting from 1.\n",
    "         Generate Tokenized Texts: Store the tokenized version of each tweet (list of tokens) in a     \n",
    "         separate list (tokenized_texts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d1a22ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3006,
     "status": "ok",
     "timestamp": 1737013432937,
     "user": {
      "displayName": "sri tulasi",
      "userId": "02259084893350954565"
     },
     "user_tz": -330
    },
    "id": "5d1a22ab",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-def790a1042875cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "104eba8e-4fd0-4a77-81d0-54184a784ec8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897\n"
     ]
    }
   ],
   "source": [
    "# Tokenization function\n",
    "def simple_tokenize(text):\n",
    "    return text.lower().split()    # convert the text into lower case and split words by space\n",
    "\n",
    "# Convert text to sequences (tokenized indices)\n",
    "word_to_index = {}        # store the word with its index form in key value pair i.e., dictionary\n",
    "tokenized_texts = []      # empty array for  tokenized text\n",
    "for text in data[\"text\"]:\n",
    "    tokens = simple_tokenize(text)\n",
    "    tokenized_texts.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_to_index:\n",
    "            word_to_index[token] = len(word_to_index) + 1  # Index starts at 1\n",
    "print(word_to_index[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ace2793-93a6-4bd9-9bf8-5fa3992891fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1737013225035,
     "user": {
      "displayName": "sri tulasi",
      "userId": "02259084893350954565"
     },
     "user_tz": -330
    },
    "id": "4ace2793-93a6-4bd9-9bf8-5fa3992891fb",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e9ea6f3bd2301519",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "ea4f4da2-b135-4e4c-a08d-a2db517ff43c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tokenized_text at an index: ['@virginamerica', 'what', '@dhepburn', 'said.'] \n",
      "\n",
      "A tokenized words in all text with a assigned number: [('@virginamerica', 1), ('what', 2), ('@dhepburn', 3), ('said.', 4), ('plus', 5), (\"you've\", 6), ('added', 7), ('commercials', 8), ('to', 9), ('the', 10), ('experience...', 11), ('tacky.', 12), ('i', 13), (\"didn't\", 14), ('today...', 15), ('must', 16), ('mean', 17), ('need', 18), ('take', 19), ('another', 20), ('trip!', 21), (\"it's\", 22), ('really', 23), ('aggressive', 24), ('blast', 25), ('obnoxious', 26), ('\"entertainment\"', 27), ('in', 28), ('your', 29), (\"guests'\", 30), ('faces', 31), ('&amp;', 32), ('they', 33), ('have', 34), ('little', 35), ('recourse', 36), ('and', 37), ('a', 38), ('big', 39), ('bad', 40), ('thing', 41), ('about', 42), ('it', 43), ('seriously', 44), ('would', 45), ('pay', 46), ('$30', 47), ('flight', 48), ('for', 49), ('seats', 50), ('that', 51), ('this', 52), ('playing.', 53), ('only', 54), ('flying', 55), ('va', 56), ('yes,', 57), ('nearly', 58), ('every', 59), ('time', 60), ('fly', 61), ('vx', 62), ('“ear', 63), ('worm”', 64), ('won’t', 65), ('go', 66), ('away', 67), (':)', 68), ('missed', 69), ('prime', 70), ('opportunity', 71), ('men', 72), ('without', 73), ('hats', 74), ('parody,', 75), ('there.', 76), ('https://t.co/mwpg7grezp', 77), ('well,', 78), (\"didn't…but\", 79), ('now', 80), ('do!', 81), (':-d', 82), ('was', 83), ('amazing,', 84), ('arrived', 85), ('an', 86), ('hour', 87), ('early.', 88), (\"you're\", 89), ('too', 90), ('good', 91), ('me.', 92), ('did', 93), ('you', 94), ('know', 95), ('suicide', 96), ('is', 97), ('second', 98), ('leading', 99), ('cause', 100)] \n",
      "\n",
      "Created Corpus with vocab_size : 26840\n"
     ]
    }
   ],
   "source": [
    "print(\"A tokenized_text at an index:\" ,tokenized_texts[0],\"\\n\") # print the Tokens in a text\n",
    "print(\"A tokenized words in all text with a assigned number:\",list(word_to_index.items())[:100],\"\\n\")  # print the word and index\n",
    "print(\"Created Corpus with vocab_size :\",len(word_to_index))  # print the word and index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237fab4",
   "metadata": {
    "id": "e237fab4",
    "tags": []
   },
   "source": [
    "### 4.Convert tokenized texts to integer sequences"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2dc928e",
   "metadata": {
    "id": "b2dc928e",
    "tags": []
   },
   "source": [
    "You are provided with a list of tokenized text sequences, where each sequence is a list of tokens (words). Your task is to:\n",
    "\n",
    "1.Determine the length of the longest sequence in the list (max_len).\n",
    "\n",
    "\n",
    "2.Convert each sequence of tokens into an integer sequence using a dictionary called word_to_index, which maps tokens to their corresponding indices. If a token is not present in the dictionary, assign it the index 0.\n",
    "\n",
    "\n",
    "3.Pad each sequence to the length of the longest sequence by appending 0 to make all sequences equal in length. The padded sequences should be stored in a NumPy array called padded_sequences.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646ad573",
   "metadata": {
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1737013778041,
     "user": {
      "displayName": "sri tulasi",
      "userId": "02259084893350954565"
     },
     "user_tz": -330
    },
    "id": "646ad573",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0e31d7ef194240d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert tokenized texts to integer sequences\n",
    "max_len = max([len(tokens) for tokens in tokenized_texts])  # Find max sentence length\n",
    "\n",
    "sequences = []\n",
    "for tokens in tokenized_texts:\n",
    "    sequence = [word_to_index.get(token, 0) for token in tokens]  # Map tokens to indices\n",
    "    sequences.append(sequence)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "padded_sequences = np.array([seq + [0] * (max_len - len(seq)) for seq in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1771f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737013780856,
     "user": {
      "displayName": "sri tulasi",
      "userId": "02259084893350954565"
     },
     "user_tz": -330
    },
    "id": "102d38a5-6e15-4ffe-9509-d020d73f2583",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-012eff8cffbddc04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "5950f3f0-cd7a-4f13-d27a-96a1e559a81a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " max length sentence : 36\n",
      "\n",
      " sample tokenized_texts : ['@virginamerica', 'and', \"it's\", 'a', 'really', 'big', 'bad', 'thing', 'about', 'it']\n",
      "\n",
      " sample sequence :\n",
      "  [1, 37, 22, 38, 23, 39, 40, 41, 42, 43]\n",
      "\n",
      " sample padded sequence of size max length:\n",
      " [ 1 37 22 38 23 39 40 41 42 43  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n max length sentence :\", max_len)\n",
    "print(\"\\n sample tokenized_texts :\",tokenized_texts[4])\n",
    "print(\"\\n sample sequence :\\n \",sequences[4])\n",
    "print(\"\\n sample padded sequence of size max length:\\n\",padded_sequences[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51159b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test Case 1 Check if sequences are padded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1124e8",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e1537bdadd29125b",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1 Passed\n"
     ]
    }
   ],
   "source": [
    "# TEST : Check if sequences are padded correctly\n",
    "def test_padding(padded_sequences):\n",
    "    assert padded_sequences.shape[1] == max_len, \"Padding did not work correctly. Sequence length mismatch.\"\n",
    "    assert all(len(seq) == max_len for seq in padded_sequences), \"Not all sequences are padded to the same length.\"\n",
    "test_padding(padded_sequences)\n",
    "\n",
    "print(\"Test Case 1 Passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f21c9",
   "metadata": {
    "id": "b77f21c9",
    "tags": []
   },
   "source": [
    "### 5. Perform mapping target  to labels \n",
    "\n",
    "You are working with a dataset containing a column called airline_sentiment, which indicates the sentiment of airline reviews. The sentiment values are categorized as positive, neutral, and negative. Your task is to:\n",
    "\n",
    "1. Map the sentiment categories to numerical labels using the following mapping:\n",
    "\n",
    "    positive → 2\n",
    "    neutral → 1\n",
    "    negative → 0\n",
    "    \n",
    "   Store the mapped values as a NumPy array in the variable labels.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cce44c1",
   "metadata": {
    "id": "0cce44c1",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-460beb27e544398e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline_sentiment category at an index: neutral\n",
      "Converted airline_sentiment category to label at an index: 1\n"
     ]
    }
   ],
   "source": [
    "###BEGIN SOLUTION\n",
    "# Prepare labels (sentiment)\n",
    "labels = data[\"airline_sentiment\"].map({\"positive\": 2, \"neutral\": 1, \"negative\": 0}).values\n",
    "###END SOLUTION\n",
    "print(\"airline_sentiment category at an index:\", data[\"airline_sentiment\"][2])\n",
    "print(\"Converted airline_sentiment category to label at an index:\",labels [2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5add91e",
   "metadata": {
    "id": "e5add91e",
    "tags": []
   },
   "source": [
    "## 6. Converting X,y to Long tensors  ; Train-test split and creating data loaders"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee516a8b",
   "metadata": {
    "id": "ee516a8b",
    "tags": []
   },
   "source": [
    "To train the model on a dataset of tweets, where each tweet has an associated sentiment label.\n",
    "You are working with text data that has been processed into padded sequences (padded_sequences) and their corresponding numerical labels (labels). Your tasks are as follows:\n",
    "\n",
    "1.Convert the data into PyTorch tensors:\n",
    "    Convert padded_sequences into a tensor of type torch.long and store it as X.\n",
    "    Convert labels into a tensor of type torch.long and store it as y.\n",
    "    Print the tensor X at a specific index (e.g., index 2) and its corresponding label from y.\n",
    "    \n",
    "2. Split the data into training and testing sets:\n",
    "    Use an 80-20 split to divide X and y into training and testing datasets. Store the results as X_train,     X_test, y_train, and y_test.\n",
    "    \n",
    "3. Create DataLoaders for the training and testing datasets:\n",
    "    Use the training and testing datasets to create PyTorch TensorDataset objects (train_dataset and \n",
    "    test_dataset).\n",
    "    Use these datasets to create DataLoader objects (train_loader and test_loader) with a batch size 64.\n",
    "    Ensure that the train_loader shuffles the data while test_loader does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c0ddad",
   "metadata": {
    "id": "61c0ddad",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d6a3656e47dc274a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X at an index: tensor([ 1, 13, 14, 15, 16, 17, 13, 18,  9, 19, 20, 21,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "y at an index: tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors\n",
    "X = torch.tensor(padded_sequences, dtype=torch.long)  # convert the padded sequence to long tensor \n",
    "y = torch.tensor(labels, dtype=torch.long)            # convert the label to long tensor\n",
    "\n",
    "print(\"X at an index:\", X[2])\n",
    "print(\"y at an index:\",y[2])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader for training and testing\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "#\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)  # batches of train or test data\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97ab64f6-7c2e-452d-8f4f-351d8dbf95ea",
   "metadata": {
    "id": "97ab64f6-7c2e-452d-8f4f-351d8dbf95ea",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4f2bda17e6da061",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "b94f99ce-b7c4-428e-f475-607b76ff2f6d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " length of train_dataset : 11712\n",
      " length of train_dataset  at an index : (tensor([1163,   94,  191, 3472,  491, 1196, 3473,   49, 2327,  764,  257,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]), tensor(0))\n",
      " length of test_dataset : 2928\n",
      " length of train_loader : 183\n",
      " length of test_loader : 46\n"
     ]
    }
   ],
   "source": [
    "print(\" length of train_dataset :\",len(train_dataset))\n",
    "print(\" length of train_dataset  at an index :\",train_dataset[0])\n",
    "print(\" length of test_dataset :\",len(test_dataset))\n",
    "print(\" length of train_loader :\",len(train_loader)) \n",
    "print(\" length of test_loader :\",len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89814cf9",
   "metadata": {
    "id": "89814cf9",
    "tags": []
   },
   "source": [
    "## 2.Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634b43e1",
   "metadata": {
    "id": "634b43e1",
    "tags": []
   },
   "source": [
    "### 7.Define the scaled dot-product attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac29d0d-521f-4901-b315-d40a3c62c8d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "You are tasked with implementing a Scaled Dot-Product Attention Mechanism, which is a core component of transformer-based models used in natural language processing. The attention mechanism helps the model focus on relevant parts of the input sequence. Your specific tasks are as follows:\n",
    "\n",
    "1.Create a PyTorch module for Scaled Dot-Product Attention by defining a class ScaledDotAttention that inherits from torch.nn.Module.\n",
    "\n",
    "2.Implement the constructor (__init__) method, which should:\n",
    "    Accept a parameter hidden_size to define the size of attention embeddings.\n",
    "    Store this value for later use.\n",
    "\n",
    "3.Implement the forward pass (forward method) to:\n",
    "    Take three input tensors: Q (query), K (key), and V (value).\n",
    "    Compute the attention scores using the scaled dot-product formula given below:\n"
   ]
  },
  {
   "attachments": {
    "5924e564-daee-421b-b303-e5eaf9150dc0.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a7f2f6d2-110f-4732-852d-323b529c2413",
   "metadata": {
    "tags": []
   },
   "source": [
    "![image.png](attachment:5924e564-daee-421b-b303-e5eaf9150dc0.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680f295-50ca-4721-9edb-6a3feb529675",
   "metadata": {
    "tags": []
   },
   "source": [
    "4.Apply the softmax function along the last dimension to obtain attention weights.\n",
    "    Compute the final output by performing a weighted sum of the values (V) using the attention weights.\n",
    "    Store the last inputs (Q, K, V) for debugging purposes.\n",
    "\n",
    "5.Return the final attention output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f92d58e",
   "metadata": {
    "id": "7f92d58e",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ead78447846b1cf2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the scaled dot-product attention mechanism\n",
    "class ScaledDotAttention(nn.Module):   #inherit the pytorch nn.module to the mechanism class\n",
    "    def __init__(self, hidden_size):   #Instantiate objects in the constructor\n",
    "        super(ScaledDotAttention, self).__init__() # inherit the scaleddotproduct\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, Q, K, V):      # method for forward pass of Scaleddotproduct class\n",
    "        # Compute scaled dot-product attention scores\n",
    "        attention_scores = torch.matmul(Q, K.transpose(1, 2)) / np.sqrt(self.hidden_size)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "        output = torch.matmul(attention_weights, V)\n",
    "\n",
    "        # Store values for debugging\n",
    "        self.last_Q = Q\n",
    "        self.last_K = K\n",
    "        self.last_V = V\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a143c9c-c581-479a-a0ca-8ac49b9382f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test Case 2 Check ScaledDotAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca1143bd",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fdcfc5728506649b",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test case 2 Passed! torch.Size([2, 4, 128])\n"
     ]
    }
   ],
   "source": [
    "# Define the test case for ScaledDotAttention\n",
    "def test_scaled_dot_attention():\n",
    "    # Initialize the attention layer with a hidden size (e.g., 128)\n",
    "    hidden_size = 128\n",
    "    attention_layer = ScaledDotAttention(hidden_size)\n",
    "    \n",
    "    # Create dummy Q, K, and V tensors for the test\n",
    "    batch_size = 2\n",
    "    seq_len = 4\n",
    "    feature_size = hidden_size\n",
    "    Q = torch.randn(batch_size, seq_len, feature_size)  # Query tensor\n",
    "    K = torch.randn(batch_size, seq_len, feature_size)  # Key tensor\n",
    "    V = torch.randn(batch_size, seq_len, feature_size)  # Value tensor\n",
    "\n",
    "    # Perform the forward pass\n",
    "    output = attention_layer(Q, K, V)\n",
    "\n",
    "    # Assert that the output shape is correct: (batch_size, seq_len, feature_size)\n",
    "    assert output.shape == (batch_size, seq_len, feature_size), f\"Expected output shape (batch_size, seq_len, feature_size), but got {output.shape}\"\n",
    "\n",
    "    # Print the output for verification\n",
    "    print(\" Test case 2 Passed!\", output.shape)\n",
    "\n",
    "# Run the test case\n",
    "test_scaled_dot_attention()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba06c5",
   "metadata": {
    "id": "48ba06c5",
    "tags": []
   },
   "source": [
    "### 8.Define the sentiment analysis model with scaled dot-product attention"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45ae1376-7f01-4c3f-80d5-a720c21c5a5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "You are tasked with implementing a Sentiment Analysis Model that incorporates Scaled Dot-Product Attention to enhance the model's performance. The model will classify text into three categories: positive, neutral, and negative sentiments. Your tasks include:\n",
    "\n",
    "1.Create a PyTorch neural network model by defining a class SentimentAnalysisModel that inherits from torch.nn.Module.\n",
    "\n",
    "2.Implement the constructor (__init__) method, which should:\n",
    "    Accept the parameters:\n",
    "        vocab_size: Size of the vocabulary.\n",
    "        embedding_dim: Dimensionality of word embeddings.\n",
    "        hidden_size: Size of the hidden layer in the LSTM.\n",
    "    Define the following layers:\n",
    "        An embedding layer (nn.Embedding) to convert input indices into dense vectors.\n",
    "        An LSTM layer (nn.LSTM) to process sequences and extract contextual information.\n",
    "    A scaled dot-product attention mechanism (ScaledDotAttention) to focus on important parts of the     \n",
    "    sequence.\n",
    "    A fully connected layer (nn.Linear) with 3 output units (for positive, neutral, negative \n",
    "    classification).\n",
    "    \n",
    "3.Implement the forward pass (forward method) to:\n",
    "    Pass the input through the embedding layer.\n",
    "    Apply the LSTM to capture sequential dependencies and obtain hidden states.\n",
    "    Use the scaled dot-product attention mechanism to refine the LSTM output.\n",
    "    Extract the last time step's output and pass it through the fully connected layer to predict \n",
    "    sentiment.\n",
    "    Print the shapes of intermediate outputs for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b53828",
   "metadata": {
    "id": "e4b53828",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6d9810e54f462a35",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the sentiment analysis model with scaled dot-product attention\n",
    "class SentimentAnalysisModel(nn.Module):  # inherit  SAModel from  nn.module\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super(SentimentAnalysisModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.attention = ScaledDotAttention(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, 3)  # 3 classes: positive, neutral, negative\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x) \n",
    "        print(\"embedded\",embedded.shape)\n",
    "        #(batch_size, sequence_length, embedding_dim)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(embedded)  # shape(batch_size, sequence_length, hidden_size) ; Hidden state ,# cell state\n",
    "        print(\"lstm_out\",lstm_out.shape)\n",
    "        # Apply scaled dot-product attention\n",
    "        attention_out = self.attention(lstm_out, lstm_out, lstm_out)  # Q, K, V are lstm_out\n",
    "        print(\"attention_out\",attention_out.shape)\n",
    "        out = attention_out[:, -1, :]  # Get the output of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2466afff-c289-4d65-8f56-d71e1ae4d464",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test Case 3 Check SentimentAnalysisModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c50a59fe",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-efc923f5273fc0c7",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded torch.Size([2, 5, 100])\n",
      "lstm_out torch.Size([2, 5, 128])\n",
      "attention_out torch.Size([2, 5, 128])\n",
      "Final output: torch.Size([2, 3])\n",
      "Test Case 3 Passed!\n"
     ]
    }
   ],
   "source": [
    "# Define the test case for SentimentAnalysisModel\n",
    "def test_sentiment_analysis_model():\n",
    "    # Initialize the model with vocab_size, embedding_dim, and hidden_size\n",
    "    vocab_size = 5000  # Example vocab size\n",
    "    embedding_dim = 100\n",
    "    hidden_size = 128\n",
    "    model = SentimentAnalysisModel(vocab_size, embedding_dim, hidden_size)\n",
    "\n",
    "    # Create dummy input data (e.g., batch size = 2, sequence length = 5)\n",
    "    batch_size = 2\n",
    "    seq_len = 5\n",
    "    dummy_input = torch.randint(0, vocab_size, (batch_size, seq_len))  # Random token indices\n",
    "\n",
    "    # Perform a forward pass\n",
    "    output = model(dummy_input)\n",
    "\n",
    "\n",
    "    # Check the shapes of intermediate outputs\n",
    "    # Extract embeddings, LSTM outputs, and attention outputs from the model\n",
    "    embedded = model.embedding(dummy_input)\n",
    "    lstm_out, (h_n, c_n) = model.lstm(embedded)\n",
    "    attention_out = model.attention(lstm_out, lstm_out, lstm_out)\n",
    "    \n",
    "    assert attention_out.shape == torch.Size([batch_size, seq_len, hidden_size]), \\\n",
    "        f\"Expected attention_out shape (batch_size, seq_len, hidden_size), but got {attention_out.shape}\"\n",
    "\n",
    "    # Print the output shapes\n",
    "    \n",
    "    print(f\"Final output: {output.shape}\")\n",
    "    print(\"Test Case 3 Passed!\")\n",
    "\n",
    "# Run the test case\n",
    "test_sentiment_analysis_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90a5c6",
   "metadata": {
    "id": "6e90a5c6",
    "tags": []
   },
   "source": [
    "### 9.Initialize  model parameters , model,loss and optimizer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ad5ab7b",
   "metadata": {
    "id": "4ad5ab7b",
    "tags": []
   },
   "source": [
    "You are building a sentiment analysis model using deep learning. Your goal is to:\n",
    "\n",
    "1.Define key model parameters based on the processed vocabulary:\n",
    "\n",
    "    Determine the vocab_size by counting the unique words in the word_to_index dictionary and adding 1 to include the padding token.\n",
    "    Set embedding_dim to 100 (representing the size of word embeddings).\n",
    "    Set hidden_size to 128 (representing the number of units in the LSTM).\n",
    "    \n",
    "2.Print the vocabulary details, including:\n",
    "\n",
    "    The number of unique words in the vocabulary.\n",
    "    The final vocabulary size including the padding token.\n",
    "    \n",
    "3.Instantiate the sentiment analysis model by creating an instance of the SentimentAnalysisModel with the computed values of vocab_size, embedding_dim, and hidden_size.\n",
    "\n",
    "4.Define the loss function and optimizer, where:\n",
    "\n",
    "    The loss function should be CrossEntropyLoss, suitable for multi-class classification.\n",
    "    The optimizer should be Adam with a learning rate of 0.001 to adjust the model parameters during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ea4ed99-6e69-4100-99a2-6b37738f17d9",
   "metadata": {
    "id": "9ea4ed99-6e69-4100-99a2-6b37738f17d9",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b5cce514abf0525b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique word indexs:  26840\n",
      "Total unique words:  26841\n"
     ]
    }
   ],
   "source": [
    "# For reference\n",
    "vocab_size = len(word_to_index) + 1  # Include padding token\n",
    "embedding_dim = 100\n",
    "hidden_size = 128\n",
    "\n",
    "print(\"Total unique word indexs: \", len(word_to_index))\n",
    "print(\"Total unique words: \",vocab_size)\n",
    "\n",
    "###BEGIN SOLUTION\n",
    "# Instantiate a model variable with SentimentAnalysisModel\n",
    "model = SentimentAnalysisModel(vocab_size, embedding_dim, hidden_size)\n",
    "\n",
    "# Define loss  and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "###END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab02e541",
   "metadata": {
    "id": "ab02e541",
    "tags": []
   },
   "source": [
    "### 5.Train the sentiment analysis model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61cba203",
   "metadata": {
    "id": "61cba203",
    "tags": []
   },
   "source": [
    "You are tasked with implementing a training loop for the sentiment analysis model using PyTorch. The training loop will optimize the model using batches of training data, evaluate performance on validation data, and track important metrics. Your tasks include:\n",
    "\n",
    "1.Define the train_model function with the following parameters:\n",
    "    model: The sentiment analysis model to be trained.\n",
    "    train_loader: DataLoader for training data.\n",
    "    val_loader: DataLoader for validation data.\n",
    "    epochs: The number of training epochs.\n",
    "    \n",
    "2.Inside the training loop, perform the following steps for each epoch:\n",
    "    Set the model to training mode using model.train().\n",
    "    Initialize tracking variables total_loss and total_acc.\n",
    "    Iterate through the batches of train_loader and perform:\n",
    "        Forward pass: Compute the model's predictions.\n",
    "        Compute loss using the criterion.\n",
    "        Backward pass: Zero the gradients, backpropagate, and update parameters using the optimizer.\n",
    "        Accumulate loss and accuracy.      \n",
    "    Print attention matrices Q, K, and V for the first batch of each epoch to verify attention behavior.\n",
    "    Compute and print average training loss and accuracy.\n",
    "    \n",
    "3. Validation step, performed after each training epoch:\n",
    "    Set the model to evaluation mode using model.eval().\n",
    "    Disable gradient computation using torch.no_grad().\n",
    "    Iterate over val_loader to compute validation loss and accuracy.\n",
    "    Print validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9f89553",
   "metadata": {
    "id": "e9f89553",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66040868a46068f7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, total_acc = 0, 0\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)       #\n",
    "            loss = criterion(outputs, labels)  # calculates the cross entropy b/n label and predicted label\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()  # initalize the gradients to zero\n",
    "            loss.backward()   # backpropagate\n",
    "            optimizer.step()  # update the gradients\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "            # Print Q, K, V for the first batch of the epoch\n",
    "            if batch_idx == 0:\n",
    "                attention_layer = model.attention\n",
    "                Q, K, V = attention_layer.last_Q, attention_layer.last_K, attention_layer.last_V\n",
    "                print(f\"Q shape: {Q.shape}\")\n",
    "                print(f\"K shape: {K.shape}\")\n",
    "                print(f\"V shape: {V.shape}\")\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_acc = total_acc / len(train_loader.dataset)\n",
    "\n",
    "        print(f\"Loss: {avg_loss:.4f}, Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()  # model eval\n",
    "        val_loss, val_acc = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                val_acc += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc /= len(val_loader.dataset)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d409df6f-870d-4160-a1cd-ea5f81406769",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test Case 4 Checking Output Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dc2e86c",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8b2013bcea03c197",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "Q shape: torch.Size([64, 5, 128])\n",
      "K shape: torch.Size([64, 5, 128])\n",
      "V shape: torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([40, 5, 100])\n",
      "lstm_out torch.Size([40, 5, 128])\n",
      "attention_out torch.Size([40, 5, 128])\n",
      "Loss: 1.0971, Accuracy: 0.3420\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([40, 5, 100])\n",
      "lstm_out torch.Size([40, 5, 128])\n",
      "attention_out torch.Size([40, 5, 128])\n",
      "Validation Loss: 1.0982, Validation Accuracy: 0.3620\n",
      "Epoch 2/2\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "Q shape: torch.Size([64, 5, 128])\n",
      "K shape: torch.Size([64, 5, 128])\n",
      "V shape: torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([40, 5, 100])\n",
      "lstm_out torch.Size([40, 5, 128])\n",
      "attention_out torch.Size([40, 5, 128])\n",
      "Loss: 1.0972, Accuracy: 0.3420\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([40, 5, 100])\n",
      "lstm_out torch.Size([40, 5, 128])\n",
      "attention_out torch.Size([40, 5, 128])\n",
      "Validation Loss: 1.0982, Validation Accuracy: 0.3620\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      "embedded torch.Size([64, 5, 100])\n",
      "lstm_out torch.Size([64, 5, 128])\n",
      "attention_out torch.Size([64, 5, 128])\n",
      " Test Case 4 Passed:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NVSHARE][WARN]: Couldn't open file /var/run/secrets/kubernetes.io/serviceaccount/namespace to read Pod namespace\n",
      "[NVSHARE][INFO]: Successfully initialized nvshare GPU\n",
      "[NVSHARE][INFO]: Client ID = 6fd9523608f8d11c\n"
     ]
    }
   ],
   "source": [
    "# Create dummy dataset for testing\n",
    "def create_dummy_dataset(batch_size=64, seq_len=5, vocab_size=5000, num_samples=1000):\n",
    "    X = torch.randint(0, vocab_size, (num_samples, seq_len))\n",
    "    y = torch.randint(0, 3, (num_samples,))  # 3 classes: 0, 1, 2\n",
    "    dataset = TensorDataset(X, y)\n",
    "    return dataset\n",
    "\n",
    "# Define the test case for training loop\n",
    "def test_train_model():\n",
    "    # Initialize model, criterion, and optimizer\n",
    "    vocab_size = 5000\n",
    "    embedding_dim = 100\n",
    "    hidden_size = 128\n",
    "    model = SentimentAnalysisModel(vocab_size, embedding_dim, hidden_size)\n",
    "\n",
    "    # Create dummy data\n",
    "    train_dataset = create_dummy_dataset()\n",
    "    val_dataset = create_dummy_dataset()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model for a few epochs (e.g., 2 epochs for testing)\n",
    "    epochs = 2\n",
    "    train_model(model, train_loader, val_loader, epochs)\n",
    "\n",
    "\n",
    "    # Ensure the output shape of the model is correct after forward pass\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        outputs = model(inputs)\n",
    "        assert outputs.shape == (inputs.shape[0], 3), f\"Expected output shape (batch_size, 3), but got {outputs.shape}\"\n",
    "\n",
    "        # Check gradients for the parameters to ensure backpropagation is working\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        if batch_idx >= 2:  # Run a few batches and then break\n",
    "            break\n",
    "\n",
    "    print(\" Test Case 4 Passed:\")\n",
    "\n",
    "# Run the test case\n",
    "test_train_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d8ce5",
   "metadata": {
    "id": "d44d8ce5",
    "tags": []
   },
   "source": [
    "## 3:  Evaluate the Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51b1df45",
   "metadata": {
    "id": "51b1df45",
    "tags": []
   },
   "source": [
    "You are tasked with training and evaluating the sentiment analysis model. The goal is to train the model for a specified number of epochs and evaluate its performance on the test dataset. Your tasks include:\n",
    "\n",
    "1.Train the model using the train_model function:\n",
    "    Set the number of epochs (epochs) to 5.\n",
    "    Call the train_model function, passing the model, training data loader (train_loader), test data  \n",
    "    loader (test_loader), and the number of epochs.\n",
    "2.Evaluate the model after training:\n",
    "    Set the model to evaluation mode using model.eval().\n",
    "    Initialize tracking variables correct and total to count correctly predicted samples.\n",
    "    Use torch.no_grad() to disable gradient calculations during inference.\n",
    "    Loop through batches in test_loader to compute predictions and count correct classifications.\n",
    "        Iterates through test_loader, extracting inputs and labels.\n",
    "        Feeds inputs into the model to get outputs.\n",
    "        Compares the predicted labels (outputs.argmax(1)) with labels.\n",
    "        Accumulates the count of correct predictions and total samples.\n",
    "    Compute overall test accuracy and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf2fc413",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-434593c6a8ed9b52",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "Q shape: torch.Size([64, 36, 128])\n",
      "K shape: torch.Size([64, 36, 128])\n",
      "V shape: torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "Loss: 0.8523, Accuracy: 0.6400\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([48, 36, 100])\n",
      "lstm_out torch.Size([48, 36, 128])\n",
      "attention_out torch.Size([48, 36, 128])\n",
      "Validation Loss: 0.7246, Validation Accuracy: 0.6913\n",
      "Epoch 2/5\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "Q shape: torch.Size([64, 36, 128])\n",
      "K shape: torch.Size([64, 36, 128])\n",
      "V shape: torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "Loss: 0.6964, Accuracy: 0.7001\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([48, 36, 100])\n",
      "lstm_out torch.Size([48, 36, 128])\n",
      "attention_out torch.Size([48, 36, 128])\n",
      "Validation Loss: 0.6532, Validation Accuracy: 0.7254\n",
      "Epoch 3/5\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "Q shape: torch.Size([64, 36, 128])\n",
      "K shape: torch.Size([64, 36, 128])\n",
      "V shape: torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "Loss: 0.5844, Accuracy: 0.7568\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([48, 36, 100])\n",
      "lstm_out torch.Size([48, 36, 128])\n",
      "attention_out torch.Size([48, 36, 128])\n",
      "Validation Loss: 0.6460, Validation Accuracy: 0.7298\n",
      "Epoch 4/5\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "Q shape: torch.Size([64, 36, 128])\n",
      "K shape: torch.Size([64, 36, 128])\n",
      "V shape: torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "Loss: 0.4722, Accuracy: 0.8132\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([48, 36, 100])\n",
      "lstm_out torch.Size([48, 36, 128])\n",
      "attention_out torch.Size([48, 36, 128])\n",
      "Validation Loss: 0.6216, Validation Accuracy: 0.7582\n",
      "Epoch 5/5\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "Q shape: torch.Size([64, 36, 128])\n",
      "K shape: torch.Size([64, 36, 128])\n",
      "V shape: torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "Loss: 0.3652, Accuracy: 0.8666\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([48, 36, 100])\n",
      "lstm_out torch.Size([48, 36, 128])\n",
      "attention_out torch.Size([48, 36, 128])\n",
      "Validation Loss: 0.6773, Validation Accuracy: 0.7667\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([64, 36, 100])\n",
      "lstm_out torch.Size([64, 36, 128])\n",
      "attention_out torch.Size([64, 36, 128])\n",
      "embedded torch.Size([48, 36, 100])\n",
      "lstm_out torch.Size([48, 36, 128])\n",
      "attention_out torch.Size([48, 36, 128])\n",
      "Test Accuracy: 0.7667\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 5\n",
    "train_model(model, train_loader, test_loader, epochs)\n",
    "###BEGIN SOLUTION\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "###END SOLUTION\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018871b2",
   "metadata": {
    "id": "018871b2",
    "tags": []
   },
   "source": [
    "## 4. Prediction on Unseen sample input"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6186fd14",
   "metadata": {
    "id": "6186fd14",
    "tags": []
   },
   "source": [
    "You are building a function to predict sentiment for a given text input using a trained deep learning model in PyTorch. Your tasks are:\n",
    "\n",
    "1.Tokenize and convert the input text into numerical indices using a predefined dictionary (word_to_index).\n",
    "    1) Each word in the input text should be mapped to its corresponding index.\n",
    "    2) If a word is not found in word_to_index, assign it an index of 0.\n",
    "\n",
    "2.Pad the sequences so that all input sentences have the same length as the longest sentence in the input batch.\n",
    "\n",
    "3.Convert the processed text into a PyTorch tensor before passing it to the trained model for prediction.\n",
    "\n",
    "4.Set the model to evaluation mode (model.eval()) and make a prediction without updating model weights (i.e., use torch.no_grad()).\n",
    "\n",
    "5.Interpret the model output:\n",
    "     1) The model will return a tensor of raw scores (logits) for each sentiment category.\n",
    "     2) Use argmax(dim=1).item() to get the predicted class index.\n",
    "     3)  Convert this index into a human-readable sentiment label using a predefined list of labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b39497b-54a6-4075-8696-a59b22d8b876",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-69d37271e63e6ff6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded torch.Size([1, 3, 100])\n",
      "lstm_out torch.Size([1, 3, 128])\n",
      "attention_out torch.Size([1, 3, 128])\n",
      "Predicted Sentiment: Neutral Comment\n"
     ]
    }
   ],
   "source": [
    "###BEGIN SOLUTION\n",
    "def predict_sentiment(model, text, word_to_index):\n",
    "    # Tokenize and convert words to indices\n",
    "    text_indices = [[word_to_index.get(word, 0) for word in simple_tokenize(t)] for t in text]\n",
    "    \n",
    "    # Pad sequences to the longest sentence\n",
    "    max_len = max(map(len, text_indices))\n",
    "    text_indices = [seq + [0] * (max_len - len(seq)) for seq in text_indices]\n",
    "\n",
    "    # Convert to tensor and predict\n",
    "    text_tensor = torch.tensor(text_indices, dtype=torch.long)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(text_tensor)\n",
    "    \n",
    "    # Get predicted sentiment\n",
    "    sentiment_labels = [\"Neutral Comment\", \"Negative Comment\", \"Positive Comment\"]\n",
    "    return f\"Predicted Sentiment: {sentiment_labels[output.argmax(dim=1).item()]}\"\n",
    "###END SOLUTION\n",
    "# predict with three unseen text\n",
    "t1 = ['Nothing special, but no complaints.']\n",
    "t2 = ['I am too excited ']  # Very happy to hear you\n",
    "t3 = ['Something went wrong']  # It's disappointing\n",
    "\n",
    "# Choose text for prediction\n",
    "unseen_text = t3 \n",
    "\n",
    "# Call prediction function\n",
    "result = predict_sentiment(model, unseen_text , word_to_index)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
