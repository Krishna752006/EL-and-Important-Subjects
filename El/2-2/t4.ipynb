{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96e1a9ba-78b1-4918-a3db-6ee1bc60164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4468670-fed2-4173-8a7b-9524f75b0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_en = \"I love AI .\"\n",
    "sentence_fr = \"J' adore l'IA .\"\n",
    "\n",
    "word_map_en = {\"<pad>\": 0, \"I\": 1, \"love\": 2, \"AI\": 3, \".\": 4}\n",
    "word_map_fr = {\"<pad>\": 0, \"J'\": 1, \"adore\": 2, \"l'IA\": 3, \".\": 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e03b53c-a032-4605-9c09-563a6441d8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4]), tensor([1, 2, 3, 4]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization\n",
    "def tokenize(text,word_map):\n",
    "    return torch.tensor([word_map[word] for word in text.split()])\n",
    "\n",
    "input_tensor=tokenize(sentence_en,word_map_en)\n",
    "target_tensor=tokenize(sentence_fr,word_map_fr)\n",
    "input_tensor,target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d3ab194-be22-462c-bc86-2eedf6f1e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#positional encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,d_model,max_len=5000):\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "        self.encoding=torch.zeros(max_len,d_model)\n",
    "        position=torch.arange(0,max_len,dtype=torch.float32).unsqueeze(1)\n",
    "        div_term=torch.exp(torch.arange(0,d_model,2).float()*-(torch.log(torch.tensor(10000.0))/d_model))\n",
    "        self.encoding[:,0::2]=torch.sin(position*div_term)\n",
    "        self.encoding[:,1::2]=torch.cos(position*div_term)\n",
    "        self.encoding=self.encoding.unsqueeze(0)\n",
    "    def forward(self,x):\n",
    "        return x+self.encoding[:,:x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9783541d-a688-4c34-8f93-ee564fc5dfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi attention mechanism\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self,d_model,num_heads):\n",
    "        super(MHA,self).__init__()\n",
    "        self.num_heads=num_heads\n",
    "        self.d_model=d_model\n",
    "        self.d_k=d_model//num_heads\n",
    "        self.d_v=d_model//num_heads\n",
    "        self.query=nn.Linear(d_model,d_model)\n",
    "        self.key=nn.Linear(d_model,d_model)\n",
    "        self.value=nn.Linear(d_model,d_model)\n",
    "        self.fc=nn.Linear(d_model,d_model)\n",
    "    def forward(self,x,mask=None):\n",
    "        batch_size,seq_len,_=x.size()\n",
    "        q=self.query(x).view(batch_size,seq_len,self.num_heads,self.d_k).transpose(1,2)\n",
    "        k=self.key(x).view(batch_size,seq_len,self.num_heads,self.d_k).transpose(1,2)\n",
    "        v=self.value(x).view(batch_size,seq_len,self.num_heads,self.d_v).transpose(1,2)\n",
    "        attn_scores=torch.matmul(q,k.transpose(-2,-1))/torch.sqrt(torch.tensor(self.d_k,dtype=torch.float32))\n",
    "        if mask is not None:\n",
    "            attn_scores=attn_scores.masked_fill(mask==0,float('-inf'))\n",
    "        attn_weights=F.softmax(attn_scores,dim=-1)\n",
    "        attn_output=torch.matmul(attn_weights,v).transpose(1,2).contiguous().view(batch_size,seq_len,self.d_model)\n",
    "        return self.fc(attn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1e6d2b30-ccd9-47f5-b2b3-b24ea26c52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed forward\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,d_model,d_ff=512):\n",
    "        super(FeedForward,self).__init__()\n",
    "        self.fc1=nn.Linear(d_model,d_ff)\n",
    "        self.fc2=nn.Linear(d_ff,d_model)\n",
    "    def forward(self,x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6ac31104-0575-42bb-99de-09c35d89f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,num_heads,d_ff=512):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.mha=MHA(d_model,num_heads)\n",
    "        self.feedforward=FeedForward(d_model,d_ff)\n",
    "        self.norm1=nn.LayerNorm(d_model)\n",
    "        self.norm2=nn.LayerNorm(d_model)\n",
    "    def forward(self,x,mask=None):\n",
    "        attn_outputs=self.mha(x,mask)\n",
    "        x=self.norm1(x+attn_outputs)\n",
    "        ff_outputs=self.feedforward(x)\n",
    "        x=self.norm2(x+ff_outputs)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "17d0b2f3-ec9e-4c01-8842-39656dd68def",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,num_heads,d_ff=512):\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        self.mha1=MHA(d_model,num_heads)\n",
    "        self.mha2=MHA(d_model,num_heads)\n",
    "        self.norm1=nn.LayerNorm(d_model)\n",
    "        self.norm2=nn.LayerNorm(d_model)\n",
    "        self.norm3=nn.LayerNorm(d_model)\n",
    "        self.feedforward=FeedForward(d_model,d_ff)\n",
    "    def forward(self,x,encoder_output,tgt_mask=None,src_mask=None):\n",
    "        attn_output1=self.mha1(x,mask=src_mask)\n",
    "        x=self.norm1(x+attn_output1)\n",
    "        attn_output2=self.mha2(x,mask=src_mask)\n",
    "        x=self.norm1(x+attn_output2)\n",
    "        ff_outputs=self.feedforward(x)\n",
    "        x=self.norm3(x+ff_outputs)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "21117953-5548-4da0-a235-069bfc2bef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,vocab_size,d_model,num_heads,num_encoder_layers,num_decoder_layers,max_len=5000):\n",
    "        super(Transformer,self).__init__()\n",
    "        self.embedding=nn.Embedding(vocab_size,d_model)\n",
    "        self.encoding=PositionalEncoding(d_model,max_len)\n",
    "        self.encoder_layers=nn.ModuleList([EncoderLayer(d_model,num_heads) for _ in range(num_encoder_layers)])\n",
    "        self.decoder_layers=nn.ModuleList([DecoderLayer(d_model,num_heads) for _ in range(num_decoder_layers)])\n",
    "        self.fc=nn.Linear(d_model,vocab_size)\n",
    "    def forward(self,src,tgt,tgt_mask=None):\n",
    "        src=self.encoding(self.embedding(src))\n",
    "        tgt=self.encoding(self.embedding(tgt))\n",
    "        \n",
    "        encoder_output=src\n",
    "        for layers in self.encoder_layers:\n",
    "            encoder_output=layers(encoder_output)\n",
    "            \n",
    "        decoder_output=tgt\n",
    "        for layers in self.decoder_layers:\n",
    "            decoder_output=layers(decoder_output,encoder_output,tgt_mask=tgt_mask)\n",
    "            \n",
    "        output=self.fc(decoder_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5b9d7686-bc25-447d-8d8d-6ffdb9d60ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_sentence,word_map_en,word_map_fr,transformer):\n",
    "    input_tensor=tokenize(input_sentence,word_map_en).unsqueeze(0)\n",
    "    tgt_mask=torch.tril(torch.ones((input_tensor.size(1),input_tensor.size(1)))).unsqueeze(0).unsqueeze(0)\n",
    "    target_tensor=torch.zeros((1,input_tensor.size(1)),dtype=torch.long)\n",
    "    output=transformer(input_tensor,target_tensor,tgt_mask)\n",
    "    softmax_output=F.softmax(output,dim=-1)\n",
    "    predicted_tokens=torch.argmax(softmax_output,dim=-1)\n",
    "    reverse_word_map_fr={v:k for k,v in word_map_fr.items()}\n",
    "    translated_sentence=[reverse_word_map_fr[token.item()] for token in predicted_tokens[0] if token!=0]\n",
    "    return \" \".join(translated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ff7c017d-4443-4ab9-856a-0b03df09ea09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adore adore adore adore'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size_en=len(word_map_en)\n",
    "vocab_size_fr=len(word_map_fr)\n",
    "d_model=128\n",
    "num_heads=8\n",
    "num_encoder_layers=6\n",
    "num_decoder_layers=6\n",
    "transformer=Transformer(vocab_size_en,d_model,num_heads,num_encoder_layers,num_decoder_layers)\n",
    "outputs=translate(sentence_en,word_map_en,word_map_fr,transformer)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c907a-125e-484b-a754-2dc50f5d9d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e3a60-7c90-4ce0-b11e-b914001a3026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
